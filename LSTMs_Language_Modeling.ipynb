{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fgonza/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "              'theme': 'league',\n",
    "              'transition': 'fade',\n",
    "              'center': 'false',\n",
    "              'overview' : 'true',\n",
    "              'start_slideshow_at': 'selected'\n",
    "})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Playing With LSTMs for Language Modeling\n",
    "[Fabio A. González](http://dis.unal.edu.co/~fgonza/), Universidad Nacional de Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chars: 600901\n",
      "Vocabulary size: 59\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read().lower()\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print(\"Total number of chars:\", len(text))\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts object purely and simply as \"the thing in itself,\" without any\n",
      "falsification taking place either on the part of the subject or the\n",
      "object. i would repeat it, however, a hundred times, that \"immediate\n",
      "certainty,\" as well as \"absolute knowledge\" and the \"thing in itself,\"\n",
      "involve a contradictio in adjecto; we really ought to free ourselves\n",
      "from the misleading significance of words! the people on their part may\n",
      "think that cognition is knowing all about things, but the philosopher\n",
      "must say to him\n"
     ]
    }
   ],
   "source": [
    "print(text[31000:31500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)           Output Shape   Param # Connected to            \n",
      "======================================================================\n",
      "lstm_1 (LSTM)          (None, 40, 128)96256   lstm_input_4[0][0]      \n",
      "______________________________________________________________________\n",
      "dense_1 (TimeDistribute(None, 40, 59) 7611    lstm_1[0][0]            \n",
      "______________________________________________________________________\n",
      "activation_1 (Activatio(None, 40, 59) 0       dense_1[0][0]           \n",
      "======================================================================\n",
      "Total params: 103867\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, vocab_size), return_sequences=True, name=\"lstm_1\"))\n",
    "model.add(TimeDistributed(Dense(vocab_size), name=\"dense_1\"))#Check names to see how to load weights\n",
    "model.add(Activation('softmax', name=\"activation_1\"))\n",
    "model.summary(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h5file = 'weights_nietzche.hdf5'\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.load_weights(h5file)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Calculating the probability of a text\n",
    "\n",
    "* The probability of a text is:  \n",
    "$$P(c_1, \\dots, c_n) = P(c_1)\\prod_{i=2}^{n}\\ P(c_i | c_{1},\\dots, c_{i-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Codify text as one-hot representation\n",
    "def parse_text(text, vocab_size, padding=False):\n",
    "    if padding:\n",
    "        X = np.zeros((1, maxlen, vocab_size), dtype=np.bool)\n",
    "    else:\n",
    "        X = np.zeros((1, len(text), vocab_size), dtype=np.bool)\n",
    "    for t, char in enumerate(text):\n",
    "        X[0, t, char_indices[char]] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate the probability of a text\n",
    "def log_likelihood(model, text):\n",
    "    probs = model.predict(parse_text(text, vocab_size, padding=True)).squeeze()\n",
    "    return sum([np.log(probs[i, char_indices[c]]) \n",
    "                 for i,c in enumerate(text[1:]) ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.7494921312\n",
      "-18.5531748161\n",
      "-40.4845399261\n"
     ]
    }
   ],
   "source": [
    "print (log_likelihood(model, \"the of faculty\"))\n",
    "print (log_likelihood(model, \"the faculty of\"))\n",
    "print (log_likelihood(model, \"thefacultyof\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Most likely phrases from a BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21.5725630657  is a philosopher kant \n",
      "-24.0264622647  is kant a philosopher \n",
      "-24.0737350786  kant a philosopher is \n",
      "-24.3340368036  a philosopher is kant \n",
      "-25.7607139803  kant is a philosopher \n",
      "-25.9217395697  a philosopher kant is \n",
      "-26.3409298765  is a kant philosopher \n",
      "-26.4319313318  kant philosopher is a \n",
      "-27.5698824866  is philosopher kant a \n",
      "-28.0389502062  a kant philosopher is \n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "bow =  ['philosopher', 'kant', 'is', 'a']\n",
    "perms = [' '+' '.join(perm)+' ' for perm in permutations(bow)]\n",
    "for p, t in sorted([(log_likelihood(model, text), text) for text in perms], reverse = True)[:10]:\n",
    "    print(p, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Least likely phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-27.7351272798 a kant is philosopher\n",
      "-27.7881720141 philosopher kant is a\n",
      "-28.7193570025 philosopher is a kant\n",
      "-29.3433935877 a is philosopher kant\n",
      "-30.0071513033 kant philosopher a is\n",
      "-30.5771951154 philosopher kant a is\n",
      "-30.5931856568 kant a is philosopher\n",
      "-32.0148858503 philosopher a kant is\n",
      "-32.6038281068 is philosopher a kant\n",
      "-33.0956074744 philosopher a is kant\n"
     ]
    }
   ],
   "source": [
    "perms = [' '.join(perm) for perm in permutations(bow)]\n",
    "for p, t in sorted([(log_likelihood(model, text), text) for text in perms], reverse = True)[-10:]:\n",
    "    print(p, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Morphological structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.47106042504 why \n",
      "-5.80633699894 y wh\n",
      "-6.51182210445  why\n",
      "-7.26245993376 hy w\n",
      "-9.79217171669 wy h\n",
      "--------------------------------------------------\n",
      "-27.7011355162 y hw\n",
      "-28.8524632454  wyh\n",
      "-32.0772004128  ywh\n",
      "-32.9385781288  hwy\n",
      "-34.9063544273  yhw\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from random import shuffle\n",
    "text = list(u' ywh')\n",
    "perms = [''.join(perm) for perm in permutations(text)]\n",
    "for p, t in sorted([(log_likelihood(model, text), text) for text in perms], reverse=True)[:5]:\n",
    "    print(p, t)\n",
    "print('-'*50)\n",
    "for p, t in sorted([(log_likelihood(model, text), text) for text in perms], reverse=True)[-5:]:\n",
    "    print(p, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating text\n",
    "\n",
    "* The model calculates the probability of the next word given the previous words:  \n",
    "$$P(c_t | c_{1}, c_{2},\\dots, c_{t-1})$$\n",
    "* We sample from the model using this conditional probability\n",
    "  ```python\n",
    "  for i in [1..n]:\n",
    "      P = predict_next() \n",
    "      bin_var = sample_binomial(temperature)\n",
    "      if bin_var:\n",
    "          c_i = sample_multinomial(P) \n",
    "      else:\n",
    "          c_i = P.argmax() \n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Function to sample an index from a probability array:\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(diversity, model, sentence, n_chars, padding=True):\n",
    "    print()\n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    #sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(n_chars):\n",
    "        x = np.zeros((1, maxlen, vocab_size))\n",
    "        if padding and len(sentence) < 40:\n",
    "            space_array = [\" \"]*(40-len(sentence))\n",
    "            for t, char in enumerate(space_array):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "        for t, char in enumerate(sentence, 40-len(sentence)):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds[-1], diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        #sys.stdout.write(next_char)\n",
    "        #sys.stdout.flush()\n",
    "    print(generated)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating with seed: \"the meaning of life is \"\n",
      "the meaning of life is to the great than it is progress\"--the most probably a standpoin and something enough in the part of the philosophers, who are experience, in the sense, that is the religion of proposition of the order, and the experiences and sometimes the \"many proposished the religion of the people, and an art of so littles, to be an aspideous thre will to the schuman in the spirit, not not all their religion of the scientific morality and consideration of the philosophical process of the soul-many of the contrary they is a strong of the most problem of the spirituality and standing, there and the conditions are the instinct and the eternal many of the same not of the logical races of the suplicald the conception, the nature with the most probably the spirituality in the univershens--and in the greater conditions, the part of all people and the delight, and all the strength of the fact that the fact that even in the formour in the history of the conscience, in the contrary, and the most more and str\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(0.4, model, 'the meaning of life is ', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Using other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chars: 1001776\n",
      "Vocabulary size: 63\n"
     ]
    }
   ],
   "source": [
    "chars = ['\\n', '\\r', ' ', '!', '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '\\x81', '\\x89', '\\x8d', '\\x91', '\\x93', '\\x97', '\\x9a', '\\xa1', '\\xa9', '\\xad', '\\xb1', '\\xb3', '\\xba', '\\xbc', '\\xbf', '\\xc2', '\\xc3']\n",
    "vocab_size = len(chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(\"Total number of chars:\", len(text))\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, vocab_size), return_sequences=True, name=\"lstm_1\"))\n",
    "model.add(TimeDistributed(Dense(vocab_size), name=\"dense_1\"))#Check names to see how to load weights\n",
    "model.add(Activation('softmax', name=\"activation_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "h5file = 'weights_bib.hdf5'\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.load_weights(h5file)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating with seed: \"el sentido de la vida es \"\n",
      "el sentido de la vida es el hijo del hombre de la verdad, y de ellos de los pecados, y ha cumplido a los hombres, y los que habían entonces que es mi padre de los hombres que tenían con ellos. \n",
      "\n",
      "12 pero estaba con ellos, y a la carne, salió vosotros es de la carne, y es de la ciudad, y la vida en él le dijo: ¿qué entranteis en el camino; 14 y le dijo: ¿qué se había a sus discípulos. 12 y le es causa de la carne. \n",
      "\n",
      "14 pero escondó a los que se habían crucho en el padre, y en la ciudad en el padre de dios y los que se habían re\n",
      "\n",
      "1 es de la verdad, y los discípulos se había en la carne, y por el señor es de la sinagoga de los hombres de los padres, y le dijo: ¿qué como estaban en la carne, y no desde los hombres habían dicho por el hijo del hombre. 22 por tanto, es camino, y le dijo: ¿qué decía: señor no se había entre el camino, y los hombres habían entonces de la ciudad de dios. \n",
      "\n",
      "8 pero se había entre el cielo y le había en la sinagoga de esta voz de la muerte, y le dijo: ¿q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(0.3, model, 'el sentido de la vida es ', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## One more dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chars: 11211916\n",
      "Vocabulary size: 129\n"
     ]
    }
   ],
   "source": [
    "chars = ['\\t', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x80', '\\x81', '\\x83', '\\x84', '\\x85', '\\x8a', '\\x8b', '\\x8c', '\\x92', '\\x93', '\\x94', '\\x97', '\\x98', '\\x99', '\\x9c', '\\x9d', '\\xa0', '\\xa1', '\\xa2', '\\xa3', '\\xa4', '\\xa5', '\\xa6', '\\xa7', '\\xa8', '\\xa9', '\\xaa', '\\xab', '\\xac', '\\xad', '\\xae', '\\xaf', '\\xb0', '\\xb1', '\\xb2', '\\xb3', '\\xb4', '\\xb6', '\\xb7', '\\xb9', '\\xba', '\\xbb', '\\xbc', '\\xbd', '\\xbf', '\\xc2', '\\xc3', '\\xc5', '\\xce', '\\xd0', '\\xd1', '\\xd7', '\\xe1', '\\xe2', '\\xe9', '\\xed', '\\xef', '\\xf1', '\\xf3']\n",
    "vocab_size = len(chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(\"Total number of chars:\", len(text))\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(maxlen, vocab_size), return_sequences=True, name=\"lstm_1\"))\n",
    "model.add(TimeDistributed(Dense(vocab_size), name=\"dense_1\"))#Check names to see how to load weights\n",
    "model.add(Activation('softmax', name=\"activation_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "h5file = 'weights_reg.hdf5'\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.load_weights(h5file)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating with seed: \"el sentido de la vida es\"\n",
      "el sentido de la vida esa maldad\n",
      "preparate con tu cantante sin ti...\n",
      "\n",
      "dale mami que te vas\n",
      "con la coche\n",
      "con el alta coming soon\n",
      "\n",
      "lo que se te converti lo de la gente\n",
      "mi espolo el papo de nada\n",
      "parte de la ghetto\n",
      "si se sienen mi calle yo te una ves\n",
      "\n",
      "white blook\n",
      "que nadie se trate de activar la vida dispuesta\n",
      "prendeen tran mi monthe garrote\n",
      "forma de la calle en de tilas y mi calle me lo di con mi corazón,\n",
      "pero no puedes ne\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(0.6, model, 'el sentido de la vida es', 400, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Training of the model\n",
    "\n",
    "This is the code used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Shape X', X.shape)\n",
    "print('Shape y', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
